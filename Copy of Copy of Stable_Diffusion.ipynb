{"cells":[{"cell_type":"markdown","metadata":{"id":"620o1BxdNbgq"},"source":["# **Stable Diffusion 2.1**\n"]},{"cell_type":"code","source":["print(\"Hello!\")"],"metadata":{"id":"q0oe_EZq3_Pe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"E3qR-vvEBWNB"}},{"cell_type":"markdown","metadata":{"id":"KQI4RX20DW_8"},"source":["# Install dependencies\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"78HoqRAB-cES"},"outputs":[],"source":["!pip install --upgrade git+https://github.com/huggingface/diffusers.git\n","# !pip install diffusers\n","!pip install --upgrade git+https://github.com/huggingface/transformers/\n","# !pip install transformers\n","!pip install accelerate==0.12.0\n","!pip install scipy\n","!pip install ftfy\n","!pip install gradio -q\n","\n","#@markdown ### ⬅️ Run this cell\n","#@markdown ---\n","#@markdown ### Install **xformers**?\n","#@markdown This will take an additional ~3.5 mins.<br>But images will generate 25-40% faster.\n","install_xformers = False #@param {type:\"boolean\"}\n","\n","if install_xformers:\n","  import os\n","  from subprocess import getoutput\n","\n","  os.system(\"pip install --extra-index-url https://download.pytorch.org/whl/cu113 torch torchvision==0.13.1+cu113\")\n","  os.system(\"pip install triton==2.0.0.dev20220701\")\n","  gpu_info = getoutput('nvidia-smi')\n","  if(\"A10G\" in gpu_info):\n","      os.system(f\"pip install -q https://github.com/camenduru/stable-diffusion-webui-colab/releases/download/0.0.15/xformers-0.0.15.dev0+4c06c79.d20221205-cp38-cp38-linux_x86_64.whl\")\n","  elif(\"T4\" in gpu_info):\n","      os.system(f\"pip install -q https://github.com/camenduru/stable-diffusion-webui-colab/releases/download/0.0.15/xformers-0.0.15.dev0+1515f77.d20221130-cp38-cp38-linux_x86_64.whl\")\n","\n","\n","# ### install xformers\n","# from IPython.utils import capture\n","# from subprocess import getoutput\n","# from re import search\n","\n","# with capture.capture_output() as cap:\n","\n","#     smi_out = getoutput('nvidia-smi')\n","#     supported = search('(T4|P100|V100|A100|K80)', smi_out)\n","\n","#     if not supported:\n","#       while True:\n","#         print(\"\\x1b[1;31mThe current GPU is not supported, try starting a new session.\\x1b[0m\")\n","#     else:\n","#       supported = supported.group(0)\n","\n","# !pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/{supported}/xformers-0.0.13.dev0-py3-none-any.whl\n","# !pip install -q https://github.com/ShivamShrirao/xformers-wheels/releases/download/4c06c79/xformers-0.0.15.dev0+4c06c79.d20221201-cp38-cp38-linux_x86_64.whl"]},{"cell_type":"markdown","metadata":{"id":"OOPHNsFYDbc0"},"source":["# Run the app"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gId0-asCBVwL"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras\n","import layers, models\n","from sklearn.model_selection import train_test_split\n","\n","# Load the preprocessed medical images and labels\n","X = np.load('medical_images.npy')\n","y = np.load('labels.npy')\n","\n","# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Define the Capsule Network architecture\n","class CapsuleNetwork(models.Model):\n","    def _init_(self, input_shape, num_classes):\n","        super(CapsuleNetwork, self)._init_()\n","\n","        # Convolutional layer\n","        self.conv1 = layers.Conv2D(filters=256, kernel_size=9, padding='valid', activation='relu', input_shape=input_shape)\n","\n","        # Primary Capsules layer\n","        self.primary_capsules = layers.Conv2D(filters=256, kernel_size=9, strides=2, padding='valid')\n","\n","        # Digit Capsules layer\n","        self.digit_capsules = layers.Dense(units=num_classes * 16, activation=None)\n","\n","        # Reshape Digit Capsules to have a shape of [batch_size, num_classes, 16]\n","        self.digit_capsules_reshape = layers.Reshape(target_shape=[num_classes, 16])\n","\n","        # Squash activation function\n","        self.squash = Squash()\n","\n","    def call(self, inputs):\n","        # Convolutional layer\n","        x = self.conv1(inputs)\n","\n","        # Primary Capsules layer\n","        x = self.primary_capsules(x)\n","        x = self.squash(x)\n","\n","        # Digit Capsules layer\n","        x = self.digit_capsules(x)\n","        x = self.digit_capsules_reshape(x)\n","        x = self.squash(x)\n","\n","        # Length of Capsule vectors\n","        lengths = tf.sqrt(tf.reduce_sum(tf.square(x), axis=-1))\n","\n","        return lengths\n","\n","# Squash activation function\n","class Squash(layers.Layer):\n","    def call(self, inputs):\n","        norm = tf.norm(inputs, axis=-1, keepdims=True)\n","        squared_norm = norm ** 2\n","        scale = squared_norm / (1 + squared_norm)\n","        return scale * inputs / norm\n","\n","# Compile the model\n","model = CapsuleNetwork(input_shape=(128, 128, 3), num_classes=2)\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1, validation_data=(X_test, y_test))\n","\n","# Evaluate the model\n","score = model.evaluate(X_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:' ,score[1])\n"]}],"metadata":{"accelerator":"GPU","colab":{"private_outputs":true,"provenance":[{"file_id":"1h2d6ILbOQ9BtNe7qqw8DG6TvdC-2zPO0","timestamp":1672290050356},{"file_id":"1skNgXiPWwXrfj3T_shpEZZfHHBCaxleQ","timestamp":1671863991972},{"file_id":"https://github.com/qunash/stable-diffusion-2-gui/blob/main/stable_diffusion_2_0.ipynb","timestamp":1671619643212}],"collapsed_sections":["KQI4RX20DW_8","OOPHNsFYDbc0"]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}